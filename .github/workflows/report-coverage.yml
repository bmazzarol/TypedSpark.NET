name: Report Coverage

on:
  push:
    branches: [ 'main' ]
  pull_request:
    branches: [ 'main' ]

jobs:
  coverage:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        project-name:
          - TypedSpark.NET
        spark-version:
          - { name: spark-3.2.1, jar: microsoft-spark-3-2_2.12-2.1.1.jar }
    
    name: ${{ matrix.project-name }} (${{ matrix.spark-version.name }})
    
    steps:
      - uses: actions/checkout@v3
      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: |
            3.1.x
            6.0.x
            7.0.x
      - name: Setup Java
        uses: actions/setup-java@v3
        with:
          java-version: 8
          distribution: zulu
      - name: Cache Spark Files
        id: cache-spark
        uses: actions/cache@v3
        env:
          cache-name: cache-spark-files
        with:
          path: |
            ./${{ matrix.spark-version.name }}-bin-hadoop2.7
            ./Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1
          key: ${{ matrix.spark-version.name }}
      - name: Setup Spark
        if: steps.cache-spark.outputs.cache-hit != 'true'
        run: |
          wget -v https://archive.apache.org/dist/spark/${{ matrix.spark-version.name }}/${{ matrix.spark-version.name }}-bin-hadoop2.7.tgz
          tar -xvf ${{ matrix.spark-version.name }}-bin-hadoop2.7.tgz
        shell: bash
      - name: Setup Spark.NET
        if: steps.cache-spark.outputs.cache-hit != 'true'
        run: |
          wget -v https://github.com/dotnet/spark/releases/download/v2.1.1/Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1.tar.gz
          tar -xvf Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1.tar.gz
        shell: bash
      - name: Test
        run: |
          declare -x DOTNET_WORKER_DIR="$(echo -n $GITHUB_WORKSPACE)/Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1/Microsoft.Spark.Worker-2.1.1"
          declare -x HADOOP_HOME="$(echo -n $GITHUB_WORKSPACE)/${{ matrix.spark-version.name }}-bin-hadoop2.7"
          declare -x SPARK_HOME="$(echo -n $GITHUB_WORKSPACE)/${{ matrix.spark-version.name }}-bin-hadoop2.7"
          declare -x PATH="$(echo $PATH):$(echo -n $SPARK_HOME):$(echo -n $HADOOP_HOME):$(echo -n $GITHUB_WORKSPACE)/${{ matrix.spark-version.name }}-bin-hadoop2.7/bin"
          declare -x SPARK_DOTNET_JAR_NAME=${{ matrix.spark-version.jar }}
          export
          dotnet test ${{ matrix.project-name }}.Tests/${{ matrix.project-name }}.Tests.csproj --collect:"XPlat Code Coverage" -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=lcov
      - name: Copy Coverage File
        run: cp ${{ matrix.project-name }}.Tests/TestResults/*/coverage.info ${{ matrix.project-name }}.Tests/TestResults/coverage.info
      - name: Coveralls
        uses: coverallsapp/github-action@master
        with:
          github-token: ${{ secrets.github_token }}
          path-to-lcov: ${{ matrix.project-name }}.Tests/TestResults/coverage.info
          flag-name: ${{ matrix.project-name }}
          parallel: true
  finish:
    needs: coverage
    runs-on: ubuntu-latest
    steps:
      - name: Coveralls Finished
        uses: coverallsapp/github-action@master
        with:
          github-token: ${{ secrets.github_token }}
          parallel-finished: true