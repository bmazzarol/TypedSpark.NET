name: Report Coverage

on:
  push:
    branches: [ 'main' ]
  pull_request:
    branches: [ 'main' ]

jobs:
  coverage:
    name: Collect Coverage
    runs-on: ubuntu-latest
    strategy:
      matrix:
        project-name:
          - TypedSpark.NET
    steps:
      - uses: actions/checkout@v3
      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: |
            3.1.x
            6.0.x
            7.0.x
      - name: Setup Java
        uses: actions/setup-java@v3
        with:
          java-version: 8
          distribution: zulu
      - name: Cache Spark Files
        id: cache-spark
        uses: actions/cache@v3
        env:
          cache-name: cache-spark-files
        with:
          path: |
            ./spark-3.0.2-bin-hadoop2.7
            ./Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1
          key: spark-3.0.2
      - name: Setup Spark
        if: steps.cache-spark.outputs.cache-hit != 'true'
        run: |
          wget -v https://archive.apache.org/dist/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz
          tar -xvf spark-3.0.2-bin-hadoop2.7.tgz
        shell: bash
      - name: Setup Spark.NET
        if: steps.cache-spark.outputs.cache-hit != 'true'
        run: |
          wget -v https://github.com/dotnet/spark/releases/download/v2.1.1/Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1.tar.gz
          tar -xvf Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1.tar.gz
        shell: bash
      - name: Test
        run: |
          declare -x DOTNET_WORKER_DIR="$(echo -n $GITHUB_WORKSPACE)/Microsoft.Spark.Worker.netcoreapp3.1.linux-x64-2.1.1/Microsoft.Spark.Worker-2.1.1"
          declare -x HADOOP_HOME="$(echo -n $GITHUB_WORKSPACE)/spark-3.0.2-bin-hadoop2.7"
          declare -x SPARK_HOME="$(echo -n $GITHUB_WORKSPACE)/spark-3.0.2-bin-hadoop2.7"
          declare -x PATH="$(echo $PATH):$(echo -n $SPARK_HOME):$(echo -n $HADOOP_HOME):$(echo -n $GITHUB_WORKSPACE)/spark-3.0.2-bin-hadoop2.7/bin"
          declare -x SPARK_DOTNET_JAR_NAME=microsoft-spark-3-0_2.12-2.1.1.jar
          export
          dotnet test ${{ matrix.project-name }}.Tests/${{ matrix.project-name }}.Tests.csproj --collect:"XPlat Code Coverage" -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=lcov
      - name: Copy Coverage File
        run: cp ${{ matrix.project-name }}.Tests/TestResults/*/coverage.info ${{ matrix.project-name }}.Tests/TestResults/coverage.info
      - name: Coveralls
        uses: coverallsapp/github-action@master
        with:
          github-token: ${{ secrets.github_token }}
          path-to-lcov: ${{ matrix.project-name }}.Tests/TestResults/coverage.info
          flag-name: ${{ matrix.project-name }}
          parallel: true
  finish:
    needs: coverage
    runs-on: ubuntu-latest
    steps:
      - name: Coveralls Finished
        uses: coverallsapp/github-action@master
        with:
          github-token: ${{ secrets.github_token }}
          parallel-finished: true